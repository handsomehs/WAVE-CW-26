A. 一次性准备（只做一次）
- 把代码放到你的 PVC
  - kgpu cd 进入共享 PVC 根目录（这个目录会在作业容器内以同一路径挂载）。
  - 在这里放你的课程仓库，例如 awave/ 目录及其 src、CMakeLists.txt 等。
- 加载模块（ASPP VM）
  - module load cmake/3.25.2 nvidia/nvhpc/24.5
  - 若 CMake 找不到 HDF5，再执行 module spider hdf5 并按提示 module load hdf5/<版本>
- 重要路径约定
  - 你提供的 run.yml 默认运行 $(KGPU_SUBMIT_DIR)/build-dev/awave
  - 因此后续请把构建目录统一命名为 build-dev，并在仓库顶层执行 kgpu create，这样变量能正确解析。

B. 本地构建（在 ASPP VM，构建产物落在 PVC 中，供容器执行）
- 进入你的仓库顶层（含 src/ 与 CMakeLists.txt）
- Release 构建
  - cmake -S src -B build-dev -DCMAKE_BUILD_TYPE=Release
  - cmake --build build-dev -j
  - 提示：ASPP.cmake 已默认设置 CUDA 架构为 80;90（A100/H100 实机+虚拟），CMakeLists 也已选用 nvc++ 并启用 OpenMP offload 与 CUDA 链接，无需再手动加旗标。
- 可选 Debug 构建（调试或 profile 用）
  - cmake -S src -B build-dbg -DCMAKE_BUILD_TYPE=RelWithDebInfo
  - cmake --build build-dbg -j

C. 如何分别测试 CPU、OpenMP、CUDA 三种实现
说明：你的可执行程序是 awave，内部同时包含 wave_cpu.cpp、wave_omp.cpp、wave_cuda.cu 三条路径。具体用哪个后端，通常通过命令行参数或环境变量选择。因为这类参数名可能在不同作业模板里略有不同，请先用：
- build-dev/awave -h
查看帮助，确认选择后端的实际开关名（常见如 --backend cpu/omp/cuda 或 --cpu/--omp/--cuda 之类）。下面用占位符 <后端开关> 表示你查到的真实参数。

1) CPU 路径（最快速做功能/正确性回归）
- 直接在 ASPP VM 的 PVC 目录跑（不占用 GPU 资源）：
  - build-dev/awave -shape 32,32,32 <后端开关: CPU>
- 如果程序内部会优先尝试 OpenMP offload，可设置
  - OMP_TARGET_OFFLOAD=DISABLED
  - 然后再运行上面的命令，确保落到纯 CPU 实现。
- 结果与日志
  - 程序输出和产生的文件（如 HDF5）都在当前 PVC 目录；不需要再从容器拷回。

2) OpenMP GPU offload 路径（需要 GPU 容器）
- 方式A：用 job YAML 批处理
  - 复制一份 run.yml 为 run-omp.yml，并在 containers[0] 下的 env 中加入：
    - OMP_TARGET_OFFLOAD=MANDATORY（强制必须 offload 到 GPU，避免静默回退到 CPU）
    - OMP_DEFAULT_DEVICE=0（可选）
  - 在 command 行于 awave 参数中加入 <后端开关: OMP>，保留 -shape 32,32,32
  - 保留 resources.requests/limits.nvidia.com/gpu: 1 与 nodeSelector（A100 MIG 1g.5gb）
  - 提交并查看日志
    - kgpu create -f run-omp.yml
    - kgpu jls 查看作业
    - kgpu logs <jobname> 看输出
- 方式B：用服务容器交互调试（推荐用于 crash/性能核对）
  - kgpu start -g 1
  - kgpu shell 进入容器交互终端（容器内已挂载你的 PVC，路径一致）
  - 环境变量：export OMP_TARGET_OFFLOAD=MANDATORY
  - 运行：build-dev/awave -shape 32,32,32 <后端开关: OMP>
  - 完成后 kgpu stop

3) CUDA 路径（需要 GPU 容器）
- 方式A：直接用你给的 run.yml（它已经请求了 1 块 GPU）
  - 如果程序默认走 CUDA，就不用改；否则在 command 的参数里补上 <后端开关: CUDA>
  - kgpu create -f run.yml
  - kgpu logs <jobname>
- 方式B：服务容器交互
  - kgpu start -g 1
  - kgpu shell
  - 运行：build-dev/awave -shape 32,32,32 <后端开关: CUDA>
  - kgpu stop

提示与习惯用法
- kgpu create -n 会把最终要提交给 K8s 的 Job YAML 打印出来，便于你检查 command、env、资源请求是否如期望。
- 所有输出（日志、生成的 HDF5/PGM 等）都会留在 PVC 当前目录；容器退出后文件还在，不必额外拷贝。

D. Profiling（在 EIDF 的 profiling 专用队列；你的 YAML 已经设置好 label）
- Nsight Systems（整体时间线/并发/重叠）
  - kgpu create -f profile-nsys.yml
  - 作业完成后，当前目录会生成 <jobname>.qdrep 等；把这些文件从 PVC 拷到你本地，用 GUI 打开分析
- Nsight Compute（单核/内存事务/占用等）
  - kgpu create -f profile-ncu.yml
  - 注意：该 YAML 已设置 HOME=$shared_pvc_remote，避免 ncu 在容器不可写 HOME 下报错
- 建议：分别对 OMP 和 CUDA 各跑一次 profile，用于报告中的对比图与瓶颈定位

E. 在 K8s 上跑“纯 CPU 作业”（可选）
- 如果希望也用 Job 跑 CPU（不占 GPU 队列），可复制 run.yml 为 run-cpu.yml，并修改：
  - 删除 resources.requests/limits 里的 nvidia.com/gpu
  - 删除/注释 nodeSelector（否则会仅落在 A100 节点）
  - command 参数改为 <后端开关: CPU>
  - kgpu create -f run-cpu.yml

F. 交互/调试小贴士
- 查看程序支持的命令行参数：build-dev/awave -h
- OpenMP offload 常用环境
  - OMP_TARGET_OFFLOAD=MANDATORY（强烈推荐）
  - OMP_DISPLAY_ENV=VERBOSE（诊断用）
- CUDA 调试（可在服务容器内）
  - cuda-gdb build-dbg/awave
  - 若要设备端调试，Debug 构建可考虑加入 -G（CMake 通过 CMAKE_CUDA_FLAGS_DEBUG 配置；注意 -G 会大幅降低性能，调完记得切回 Release）
- 常见坑
  - 在非 PVC 目录构建或运行：容器内看不到你的构建产物或输出
  - 在仓库子目录提交 kgpu create：$(KGPU_SUBMIT_DIR) 解析成了子目录，路径不对；建议总在仓库顶层提交
  - HDF5 未找到：在 VM 上先 module spider hdf5 并加载一个可用版本后再 cmake
  - OMP 路径没有真正 offload：未设置 OMP_TARGET_OFFLOAD=MANDATORY 时，可能静默回退到 CPU

G. 针对“其他练习”的通用模式（negate / reconstruct / rmsnorm 等）
- 一律先在 PVC 里本地构建
  - 例如 C 版本：cmake -S src_c -B build；cmake --build build
  - 例如 rmsnorm：cmake -S . -B build -DCMAKE_BUILD_TYPE=Release -DCMAKE_CUDA_ARCHITECTURES=80-real
- 运行
  - 简单/CPU 练习：直接在 VM 上运行 build/可执行文件
  - 需要 GPU 的：复制你的 run.yml，改 command 为相应可执行与参数；或用 kgpu start -g 1 + kgpu shell 交互跑
- Profiling
  - 用 profile-nsys.yml / profile-ncu.yml 模板，按需调整 command 和输出文件名前缀

H. 提交打包（课程需要时）
- 在仓库根目录执行：
  - ./make_submission.sh -e Bxxxxxx -r /path/to/report.pdf
- 脚本会检查只修改了 wave_cuda.cu 与 wave_omp.cpp，两者之外的源码未改动，以保证评测一致性

I. 一组可直接使用的命令清单（按后端）
- CPU（本机 VM）
  - build-dev/awave -shape 32,32,32 <后端开关: CPU>
- OpenMP（GPU 容器）
  - kgpu create -f run-omp.yml（env: OMP_TARGET_OFFLOAD=MANDATORY；命令行含 <后端开关: OMP>）
  - 或交互：kgpu start -g 1 → kgpu shell → export OMP_TARGET_OFFLOAD=MANDATORY → build-dev/awave -shape 32,32,32 <OMP>
- CUDA（GPU 容器）
  - kgpu create -f run.yml（若默认非 CUDA，则给 awave 增加 <CUDA> 参数）
  - 或交互：kgpu start -g 1 → kgpu shell → build-dev/awave -shape 32,32,32 <CUDA>

